#!/usr/bin/env python

import os
import sys
import argparse

sys.stdout.flush()

parser = argparse.ArgumentParser(formatter_class = argparse.ArgumentDefaultsHelpFormatter)
parser.add_argument("-D", "--DAVID", help="Use this flag to perform DAVID GO enrichment analysis", action="store_true")
parser.add_argument("-i", "--inputFolder", help="Cuffdiff output folder")
parser.add_argument("-o", "--outputFolder", help="Output folder")
parser.add_argument("-G", "--originalGTF", help="Original/downloaded GTF")
parser.add_argument("-C", "--cuffcompareGTF", help="Merged cuffcompared GTF")
parser.add_argument("-f", "--inputFiles", help="Implies -s. Use this option to select which *.diff files you wish to analyse.'.", default='gene_exp.diff promoters.diff splicing.diff cds.diff isoform_exp.diff')
parser.add_argument("-s", "--shortOutputName", help="Use this option to select a short outpput name for each *.diff file used in '-f'. No '.' (dots) allowed.", default='geneexp prom splic cds iso')
parser.add_argument("--sigOnly", help="Only create report tables for cuffdiff-labeled significantly changed genes", action="store_true")
parser.add_argument("--TSV", help="For p values > = 0.05 write tables as tab separated values", action="store_true")
parser.add_argument("--TSVall",help="Save p < 0.05 save tables as tab separated values in a folder called TSV", action="store_true")
parser.add_argument("--description", help="Get a description of what this script does.", action="store_true")
parser.add_argument("--listMarts", help="List biomaRt Marts",action="store_true")
parser.add_argument("--mart", help="Your mart of choice.", default='ENSEMBL_MART_ENSEMBL')
parser.add_argument("--listDatasets", help="List datasets for your mart", action="store_true")
parser.add_argument("--dataset", help="Dataset of your choice.", default='celegans_gene_ensembl')
parser.add_argument("--listFilters", help="List available filters", action="store_true")
parser.add_argument("--filter", help="Filter to use to identify your genes.", default='ensembl_gene_id')
parser.add_argument("--listAttributes", help="List available attributes for your dataset.", action="store_true")
parser.add_argument("--outputBiotypes", help="Outputs/attributes for your biotypes data. Order has to be kept, ie. first IDs then biotype.", default='ensembl_gene_id gene_biotype')
parser.add_argument("--outputGoterms", help="Outputs/attributes for your goterms data. Order has to be kept, ie. 1st gene_id, then go_id, then go_term_name", default='ensembl_gene_id go_id name_1006')
parser.add_argument("--listKEGGorganisms", help="List KEGG organisms.", action="store_true")
parser.add_argument("--KEGGorg", help="KEGG organism.", default='cel')
parser.add_argument("--findKEGGdb", help="KEGG has DB identifier for each linked DB. Use this function to find the label of your DB, eg: 'ensembl-hsa', 'FlyBase'. This option requires --originalGTF and --KEGGorg", action="store_true")
parser.add_argument("--KEGGdb", help="KEGG database linked to your ensembl organism.", default='EnsemblGenomes-Gn')
parser.add_argument("--DAVIDid", help="DAVID's id for your dataset. List of ids available in http://david.abcc.ncifcrf.gov/content.jsp?file=DAVID_API.html#input_list", default='WORMBASE_GENE_ID')
parser.add_argument("--DAVIDcat", help="DAVID's categories you wish to analyse. List of available categories in https://david.ncifcrf.gov/content.jsp?file=DAVID_API.html#approved_list.", default='GOTERM_BP_FAT,GOTERM_CC_FAT,GOTERM_MF_FAT,KEGG_PATHWAY,BIOCARTA,PFAM,PROSITE')
parser.add_argument("-u", "--DAVIDuser", help="Your DAVID's user id. example: 'John.Doe@age.mpg.de'")
args = parser.parse_args()

if args.description:
    print "\nThis script annotates gene_exp.diff, promoters.diff, splicing.diff, cds.diff, and isoform_exp.diff cuffdiff tables. \
It generates 1 file for all results, 1 file for p<0.05, and 1 file/input table for q<0.05. \nFor significant values (i.e. q<0.05) it also generates \
tables containg all pair-wise comparisons in different sheets as well as gene ontology enrichment files for biological processes (BP), \
cellular component (CC), and molecular function (MF).\n \nRequired python packages:\na) pip install --user pandas==0.15.2 \nb) pip \
install --user numpy==1.9.2 \nc) pip install --user rpy2==2.5.6 \nd) pip install --user suds==0.4 \ne) pip install --user openpyxl==2.1.4 \n \nRequired R packages: \nlibrary('biomaRt')\
 \n \nRequired arguments: \n-i, -o, -G, -C \n \nExample: \nannotate_cuffdiff_output.py -D -u John.Doe@age.mpg.de -i /path/to/cuffdiff_output_folder \
-G /path/to/original.gtf -C /path/to/merged_and_compared.gtf -o /path/to/python_output_folder\
\n\n*************************************\nDeveloped by Jorge Boucas at the group for Computational RNA Biology and Ageing of the Max Planck Institute for Biology of Ageing \n\njorge.boucas@age.mpg.de\n\n"
    sys.exit(0)

import pandas as pd
import numpy as np
#import rpy2.robjects as robjects
#from rpy2.robjects.packages import importr
import time
from datetime import datetime
import shutil
from urllib import urlopen
import AGEpy.AGEpy as age


############### FUNCTIONS ############
"""
def retrieve_GTF_field(field,gtf):
    field = pd.DataFrame(gtf[8].str.split(field).tolist())[1]
    field = field.astype(str)
    field = pd.DataFrame(field.str.split(';',1).tolist())
    field = pd.DataFrame(field[0].str.split('"').tolist())[1]
    field = pd.DataFrame(field)
    return field

def list_KEGG_organisms():
    organisms=urlopen("http://rest.kegg.jp/list/organism").read()
    organisms=organisms.split("\n")
    for o in organisms:
        o=o.split("\t")
        print str(o[1]), str(o[2])
        sys.stdout.flush()

def find_KEGG_ensemblDB(organism,ens_ids):
    all_genes=urlopen("http://rest.kegg.jp/list/"+organism).read()
    all_genes=all_genes.split("\n")
    dbs=[]
    while len(dbs) == 0:
        for g in all_genes:
            if len(dbs) == 0:
                kid = g.split("\t")[0]
                gene=urlopen("http://rest.kegg.jp/get/"+kid).read()
                DBLINKS=gene.split("\n")
                DBLINKS=[ s for s in DBLINKS if ":" in s ]
                for d in DBLINKS:
                    test=d.split(" ")
                    test=test[len(test)-1]
                    if test in ens_ids:
                        DBLINK=[ s for s in DBLINKS if test in s ]
                        DBLINK=DBLINK[0].split(":")
                        DBLINK=DBLINK[len(DBLINK)-2]
                        dbs.append(DBLINK)
            else:
                break
    ens_db=dbs[0].split(" ")
    ens_db=ens_db[len(ens_db)-1]
    test_db=urlopen("http://rest.genome.jp/link/"+ens_db+"/"+organism).read()
    test_db=test_db.split("\n")
    if len(test_db) == 1:
        print "For "+organism+" the following db was found: "+ens_db
        print "This database does not seem to be valid KEGG-linked database identifier"
        print "For \n'hsa' use 'ensembl-hsa'\n'mmu' use 'ensembl-mmu'\n'cel' use 'EnsemblGenomes-Gn'\n'dme' use 'FlyBase'" 
        sys.stdout.flush()
    else:
        print "For "+organism+" the following db was found: "+ens_db
        sys.stdout.flush()
    return ens_db

def ensembl_to_kegg(organism,ens_db):
    print "KEGG API: http://rest.genome.jp/link/"+ens_db+"/"+organism
    sys.stdout.flush()
    kegg_ens=urlopen("http://rest.genome.jp/link/"+ens_db+"/"+organism).read()
    kegg_ens=kegg_ens.split("\n")
    final=[]
    for i in kegg_ens:
        final.append(i.split("\t"))
    df=pd.DataFrame(final[0:len(final)-1])[[0,1]]
    ens_id=pd.DataFrame(df[1].str.split(":").tolist())[1]
    df=pd.concat([df,ens_id],axis=1)
    df.columns=['KEGGid','ensDB','ENSid']
    df=df[['KEGGid','ENSid']]
    return df
    
def KEGG_paths(organism):
    print "KEGG API: http://rest.kegg.jp/list/pathway/"+organism
    sys.stdout.flush()
    kegg_paths=urlopen("http://rest.kegg.jp/list/pathway/"+organism).read()
    kegg_paths=kegg_paths.split("\n")
    final=[]
    for k in kegg_paths:
        final.append(k.split("\t"))
    df=pd.DataFrame(final[0:len(final)-1])[[0,1]]
    df.columns=['pathID','pathName']
    print "Collecting genes for " + str(len(df)) + " pathways"
    sys.stdout.flush()
    df_pg=pd.DataFrame()
    for i in df['pathID'].tolist():
        print i+" ",
        sys.stdout.flush()
        path_genes=urlopen("http://rest.kegg.jp/link/genes/"+i).read()
        path_genes=path_genes.split("\n")
        final=[]
        for k in path_genes:
            final.append(k.split("\t"))
        final.pop()
        if len(final[0]) is not 2:
          print " skipped (no genes found in data)"
          continue
        print str(len(final)) + " gene(s) assigned"
        df_tmp=pd.DataFrame(final[0:len(final)])[[0,1]]
        df_tmp.columns=['pathID','KEGGid']
        df_pg=pd.concat([df_pg,df_tmp])
    df=pd.merge(df,df_pg,on=["pathID"], how="outer")
    KEGGids=list(set(df['KEGGid'].tolist()))
    print "Merging final table"
    sys.stdout.flush()
    df_final=pd.DataFrame()
    for k in KEGGids:
        df_tmp=df[df['KEGGid']==k]
        pathIDs=", ".join(df_tmp['pathID'].tolist())
        pathName=", ".join(df_tmp['pathName'].tolist())
        d={'KEGGid':k,'pathIDs':pathIDs,'pathName':pathName}
        df_tmp=pd.DataFrame(d,index=[0])
        df_final=pd.concat([df_final,df_tmp])
    df_final=df_final.dropna()
    return df_final

def DAVIDenrich(listF, idType, bgF='', resF='', bgName = 'Background1',listName='List1', category = '', thd=0.1, ct=2):
    # adapted from HuangYi @ 20110424 as available on https://david.ncifcrf.gov
    #import ssl
    #ssl._create_default_https_context = ssl._create_unverified_context
    from suds.client import Client
    import os
    import ssl # fix
    ssl._create_default_https_context = ssl._create_unverified_context # fix

    if len(listF) > 0 and os.path.exists(listF):
        inputListIds = ','.join(open(listF).read().split('\n'))
        print 'List loaded.'
        sys.stdout.flush()
    else:
        print 'No list loaded.'
        sys.stdout.flush()
        raise

    flagBg = False
    if len(bgF) > 0 and os.path.exists(bgF):
        inputBgIds = ','.join(open(bgF).read().split('\n'))
        flagBg = True
        print 'Use file background.'
        sys.stdout.flush()
    else:
        print 'Use default background.'
        sys.stdout.flush()
    
    client = Client('https://david.ncifcrf.gov/webservice/services/DAVIDWebService?wsdl') # new https url
    client.wsdl.services[0].setlocation('https://david.ncifcrf.gov/webservice/services/DAVIDWebService.DAVIDWebServiceHttpSoap11Endpoint/') # fix
    print 'User Authentication:',client.service.authenticate(args.DAVIDuser)
    sys.stdout.flush()

    listType = 0
    size=client.service.addList(inputListIds,idType,listName,listType)
    #print 'Percentage mapped(list):', client.service.addList(inputListIds,idType,listName,listType)
    print 'Percentage mapped(list): %s' %str(size)
    sys.stdout.flush()
    if float(size) > float(0):

        if flagBg:
            listType = 1
            print 'Percentage mapped(background):', client.service.addList(inputBgIds,idType,bgName,listType)
            sys.stdout.flush()

        print 'Use categories:', client.service.setCategories(category)
        sys.stdout.flush()

        chartReport = client.service.getChartReport(thd,ct)
        chartRow = len(chartReport)
        print 'Total chart records:',chartRow
        sys.stdout.flush()

        if len(resF) == 0 or not os.path.exists(resF):
            if flagBg:
                resF = listF + '.withBG.chartReport'
            else:
                resF = listF + '.chartReport'
        with open(resF, 'w') as fOut:
            fOut.write('Category\tTerm\tCount\t%\tPvalue\tGenes\tList Total\tPop Hits\tPop Total\tFold Enrichment\tBonferroni\tBenjamini\tFDR\n')
            for row in chartReport:
                rowDict = dict(row)
                categoryName = str(rowDict['categoryName'])
                termName = str(rowDict['termName'])
                listHits = str(rowDict['listHits'])
                percent = str(rowDict['percent'])
                ease = str(rowDict['ease'])
                Genes = str(rowDict['geneIds'])
                listTotals = str(rowDict['listTotals'])
                popHits = str(rowDict['popHits'])
                popTotals = str(rowDict['popTotals'])
                foldEnrichment = str(rowDict['foldEnrichment'])
                bonferroni = str(rowDict['bonferroni'])
                benjamini = str(rowDict['benjamini'])
                FDR = str(rowDict['afdr'])
                rowList = [categoryName,termName,listHits,percent,ease,Genes,listTotals,popHits,popTotals,foldEnrichment,bonferroni,benjamini,FDR]
                fOut.write('\t'.join(rowList)+'\n')
            print 'write file:', resF, 'finished!'
            sys.stdout.flush()

def DAVID_get(cat, filtered_table, all_genes_table):
    IDs_table = pd.merge(filtered_table, all_genes_table, how='left', left_on='identifier', right_on='g_name')
    IDs_table = IDs_table[['g_id']].dropna()
    IDs_table.to_csv('targets_tmp.txt',sep='\t',header=False,index=False)

    background = all_genes_table[['g_id']].dropna()
    background.to_csv('background_tmp.txt',sep='\t',header=False,index=False)

    DAVIDenrich(listF = './targets_tmp.txt', bgF = './background_tmp.txt', idType = DAVID_id, bgName = 'all_RNAseq_genes', listName = 'changed_genes', category = cat)
    if os.path.isfile('targets_tmp.txt.withBG.chartReport'):
        enrich=pd.read_csv('targets_tmp.txt.withBG.chartReport',sep='\t')
        os.remove('targets_tmp.txt.withBG.chartReport')
        terms=enrich['Term'].tolist()
        enrichN=pd.DataFrame()
        for term in terms:
            tmp=enrich[enrich['Term']==term]
            tmp=tmp.reset_index(drop=True)
            ids=tmp.xs(0)['Genes']
            ids=pd.DataFrame(data=ids.split(", "))
            ids.columns=['g_id']
            ids['g_id']=ids['g_id'].map(str.lower)
            all_genes_table['g_id']=all_genes_table['g_id'].map(str.lower)
            ids=pd.merge(ids, all_genes_table, how='left', left_on='g_id', right_on='g_id')
            names=ids['g_name'].tolist()
            names = ', '.join(names)
            tmp=tmp.replace(to_replace=tmp.xs(0)['Genes'], value=names)
            enrichN=pd.concat([enrichN, tmp])
        enrichN=enrichN.reset_index(drop=True)

    else:
        enrichN=pd.DataFrame()

    os.remove('targets_tmp.txt')
    os.remove('background_tmp.txt')

    return enrichN

"""


if args.listMarts:
    print(age.databasesBM())
    sys.exit(0)

if args.listDatasets:
    print(age.datasetsBM())
    sys.exit(0)

if args.listFilters:
    print(age.filtersBM(args.dataset))
    sys.exit(0)

if args.listAttributes:
    print(age.attributesBM(args.dataset))
    sys.exit(0)

if args.listKEGGorganisms:
    print(age.organismsKEGG())
    sys.exit(0)

if args.findKEGGdb:
    print "This option requires --originalGTF"
    sys.stdout.flush()
    gtf=age.readGTF(os.path.realpath(args.originalGTF))
    print "GTF imported"
    sys.stdout.flush()
    #gtf = gtf.astype(str)
    gene_id = age.retrieve_GTF_field('gene_id',gtf)
    gene_id = gene_id['gene_id'].tolist()
    print(age.databasesKEGG(args.KEGGorg,gene_id))
    sys.exit(0)


################### paths to files #########################
diff_out = os.path.realpath(args.inputFolder)
if not args.originalGTF:
  print "Error: no original GTF file provided"
  sys.exit(65) 
  # else on 'os.path.realpath'
  #AttributeError: 'NoneType' object has no attribute 'startswith'
  #Segmentation fault
original_gtf = os.path.realpath(args.originalGTF)
if not args.cuffcompareGTF:
  print "Error: no cuffcompare GTF file provided"
  sys.exit(65)
merged_fixed_gtf = os.path.realpath(args.cuffcompareGTF)
python_output = args.outputFolder
genomes_folder=original_gtf.split('/')
genomes_folder=genomes_folder[0:len(genomes_folder)-1]
genomes_folder="/".join(genomes_folder)

if not os.path.exists(python_output):
    os.makedirs(python_output)
python_output=os.path.realpath(python_output)

if args.TSVall:
    if not os.path.exists(python_output+"/TSV"):
        os.makedirs(python_output+"/TSV")
    TSVout=os.path.realpath(python_output+"/TSV")+"/"

print "\nInput folder: "+diff_out
sys.stdout.flush()
print "Output folder: "+python_output
sys.stdout.flush()
print "Original GTF: "+original_gtf
sys.stdout.flush()
print "Cuffcompare curated GTF: "+merged_fixed_gtf
sys.stdout.flush()
print "Files being analysed: "+args.inputFiles
sys.stdout.flush()
print "Short output labels: "+args.shortOutputName
sys.stdout.flush()

if args.sigOnly:
    print "\nReporting only significantly changed genes"
    sig_choice = ['yes']
    label_choice = ['diff_sig']
else:
    sig_choice = [0.05, 2, 'yes']
    label_choice = ['diff_p.05','diff_all','diff_sig']

if args.DAVID:
    print "\nPerforming DAVID GO enrichment analysis"
    print "\nYour DAVID user ID: "+args.DAVIDuser
else:
    print "\nUse -D if you want to perform DAVID GO enrichment analysis"

sys.stdout.flush()

in_files=args.inputFiles
in_files=in_files.split()

out_labels=args.shortOutputName
out_labels=out_labels.split()

out_biot=args.outputBiotypes
out_biot=out_biot.split()

out_go=args.outputGoterms
out_go=out_go.split()

############### Set Biomart resources ######################
dataset = args.dataset
data_filter = args.filter # filter for gene_id in GTF file, 'link_ensembl_gene_id'
data_output_biotypes = out_biot # order needs to be kept i.e. id, biotype
data_output_goterms = out_go # order needs to be kept i.e. id, go_id, go_name
############################################################

############### Check DAVID's ID for your set ######################
# http://david.abcc.ncifcrf.gov/content.jsp?file=DAVID_API.html#input_list
DAVID_id=args.DAVIDid
####################################################################

###################### START #####################

os.chdir(diff_out)

########## Get list of gene names and respective ids present in the data set

if os.path.isfile(python_output+'/genes_table.txt'):
    print "\nUsing already existing list of gene names and ids"
    sys.stdout.flush()
    genes=pd.read_table(python_output+'/genes_table.txt')
    genes = genes['gene_id'].tolist()

else:
    print "\nGetting list of gene names and respective ids present in the data set"
    sys.stdout.flush()
    genes = pd.DataFrame()
    for file in ['gene_exp.diff', 'promoters.diff', 'splicing.diff', 'cds.diff', 'isoform_exp.diff']:
        df = pd.read_table(file)
        df = df[['gene']]
        genes = pd.concat([genes,df]).drop_duplicates()
    genes = genes.astype(str)
    genes = pd.DataFrame(genes.gene.str.split(',').tolist())[0]
    genes = genes.drop_duplicates()
    genes = genes.tolist()
    print "Imported list of differentially regulated genes"
    sys.stdout.flush()

    #gtf = pd.read_table(original_gtf, sep='\t', comment="#", header=None, dtype=str)
    gtf=age.readGTF(original_gtf)
    print "GTF imported"
    sys.stdout.flush()
    #gtf = gtf.astype(str)

    gene_name = age.retrieve_GTF_field('gene_name',gtf)
    print "Read gene names from GTF"
    sys.stdout.flush()

    gene_id = age.retrieve_GTF_field('gene_id',gtf)
    print "Read gene ids from GTF"
    sys.stdout.flush()

    name_id = pd.concat([gene_name, gene_id], axis=1).drop_duplicates()
    #name_id.columns = ['g_name','g_id']
    name_id = name_id[name_id['gene_name'].isin(genes)]
    print "Generated Names/IDs table"
    sys.stdout.flush()

    genes = name_id['gene_id'].tolist()

    name_id.to_csv(python_output+'/genes_table.txt', sep="\t",index=False)

    del gtf, gene_name, gene_id, name_id


# Use BioMart to retrieve biotypes and gene ontoloty information

if os.path.isfile(genomes_folder+'/biotypes_go_raw.txt'):
    print "\nCopying already existing biotypes_go_raw.txt file from genomes folder: "+str(genomes_folder)+"."
    sys.stdout.flush()
    shutil.copy(genomes_folder+'/biotypes_go_raw.txt', python_output+'/biotypes_go_raw.txt')

elif os.path.isfile(python_output+'/biotypes_go_raw.txt'):
    print "\nUsing already existing biotypes_go_raw.txt file"
    sys.stdout.flush()

else:
    print "\nRetrieving biotypes and gene ontoloy information"
    sys.stdout.flush()
    biotypes=age.queryBM(data_filter,genes,data_output_biotypes,args.dataset)
    biotypes.columns=[data_filter,data_output_biotypes[1]]
    goterms=age.queryBM(data_filter,genes,data_output_goterms,args.dataset)
    goterms.columns=[data_filter,data_output_goterms[1],data_output_goterms[2]]
    bio_go=pd.merge(biotypes,goterms,on=data_filter,how="outer")
    bio_go.to_csv(python_output+'/biotypes_go_raw.txt', quote=False, index=False, sep='\t', row_names=False)


# generate biotypes and go terms table using R/biomart output table.

if os.path.isfile(genomes_folder+'/biotypes_go.txt'):
    print "\nCopying already existing biotypes_go.txt file from genomes folder: "+str(genomes_folder)+"."
    sys.stdout.flush()
    shutil.copy(genomes_folder+'/biotypes_go.txt', python_output+'/biotypes_go.txt')

elif os.path.isfile(python_output+'/biotypes_go.txt'):
    print "\nUsing already existing biotypes_go.txt file"
    sys.stdout.flush()
else:
    print "\nGenerating final biotypes and GO terms table"
    sys.stdout.flush()
    name_id = pd.read_table(python_output+"/genes_table.txt", sep="\t")
    ontology = pd.read_table(python_output+"/biotypes_go_raw.txt")
    ontology.columns = ['gene_id','gene_biotype','GO_id','GO_term']
    ontology = pd.merge(name_id, ontology, how='outer', on='gene_id')
    ontology = ontology[['gene_name','gene_biotype','GO_id','GO_term']]
    ontology.columns = ['gene_name','gene_biotype','GO_id','GO_term']

    final = pd.DataFrame(columns = ['gene_name','gene_biotype','GO_id','GO_term'])

    genes = ontology[['gene_name']]
    genes = genes.drop_duplicates()
    for gene in list(genes.gene_name):
        ontology_gene = ontology[ontology['gene_name'] == gene]
        ontology_gene_go = ontology_gene[['GO_id','GO_term']]
        if len(ontology_gene_go.index) >= 1:
            ontology_gene_go = ontology_gene_go.transpose()
            ontology_gene_go.to_csv("tmp.txt", sep=";", header=False, index=False)
            ontology_gene_go_number = pd.read_table("tmp.txt", sep ="\t", header=None, nrows = 1)
            ontology_gene_go_name = pd.read_table("tmp.txt", sep ="\t", header=None, skiprows=1, nrows = 1)
            ontology_gene_go = pd.concat([ontology_gene_go_number, ontology_gene_go_name], axis=1)
            ontology_gene_go.columns = ['GO_id','GO_term']
        else:
            ontology_gene_go = pd.DataFrame(columns = ['GO_id','GO_term'])

        ontology_gene = ontology_gene[['gene_name','gene_biotype']].drop_duplicates()
        ontology_gene_go = ontology_gene_go.reset_index()
        ontology_gene = ontology_gene.reset_index()
        ontology_gene = pd.concat([ontology_gene, ontology_gene_go], axis = 1)
        ontology_gene = ontology_gene[['gene_name','gene_biotype','GO_id','GO_term']]
        final = pd.concat([final, ontology_gene])
    os.remove("tmp.txt")
    final.reset_index()
    final=final[['gene_name','gene_biotype','GO_id','GO_term']]
    final.to_csv(python_output+"/biotypes_go.txt", sep= "\t")

    del name_id, ontology, genes, ontology_gene, ontology_gene_go, ontology_gene_go_number, ontology_gene_go_name, final

# generate KEGG table

if os.path.isfile(genomes_folder+'/KEGG.txt'):
    print "\nCopying already existing KEGG.txt file from genomes folder: "+str(genomes_folder)+"."
    sys.stdout.flush()
    shutil.copy(genomes_folder+'/KEGG.txt', python_output+'/KEGG.txt')

elif os.path.isfile(python_output+'/KEGG.txt'):
    print "\nUsing already existing KEGG.txt file"
    sys.stdout.flush()

else:
    print "\n%s\tGenerating KEGG table\n" %(str(datetime.now())[:16])
    sys.stdout.flush()
    #names_KEGGids=age.idsKEGG(args.KEGGorg)
    kegg_ens=age.ensembl_to_kegg(args.KEGGorg,args.KEGGdb)
    paths = age.pathwaysKEGG(args.KEGGorg)
    #paths=KEGG_paths(args.KEGGorg)
    df=pd.merge(kegg_ens,paths,on=['KEGGid'],how='outer')    
    df=df[['ENSid','KEGGid','pathIDs','pathName']]
    df.columns=['gene_id','KEGGid','pathIDs','pathName']
    name_id = pd.read_table(python_output+"/genes_table.txt", sep="\t")
    df=pd.merge(name_id,df,on=['gene_id'],how='left')
    df.to_csv(python_output+"/KEGG.txt", sep= "\t", index=False)
    del kegg_ens,paths,df,name_id


# create excel report tables
if args.TSV:
    print "\nCreating excel report tables"
    sys.stdout.flush()

bio_go = pd.read_table(python_output+"/biotypes_go.txt", sep= "\t")
name_id = pd.read_table(python_output+"/genes_table.txt", sep="\t")
KEGG = pd.read_table(python_output+"/KEGG.txt", sep="\t", usecols=['gene_name','KEGGid','pathIDs','pathName'])
KEGG.columns=['identifier','KEGG_ids','KEGG_pathIDS','KEGG_pathNames' ]

for sig, label in zip(sig_choice,label_choice):
    if sig != 'yes':
        if sig >= 1:
            if args.TSV:
                print "For "+str(label)+" files will be saved as tsv"
                sys.stdout.flush()
            else:
                writer = pd.ExcelWriter(python_output+'/'+label+'.xlsx')
                print "\nWritting table "+label+".xlsx"
                sys.stdout.flush()
    
        else:
            if args.TSVall:
                print "Saving files as TSV in %s" %TSVout
                sys.stdout.flush()
            else:
                writer = pd.ExcelWriter(python_output+'/'+label+'.xlsx')
                print "\nWritting table "+label+".xlsx"
                sys.stdout.flush()

    for imp, outshort in zip(in_files, out_labels):
        df = pd.read_table(imp)
        if len(df) == 0:
            print "\n%s table is empty. Make sure the GTF reference you used for cuffdiff contains p_ids." %imp
        else:
            print "\nWorking on "+imp
            sys.stdout.flush()

            if sig == 'yes':
                if not args.TSVall:
                    writer = pd.ExcelWriter(python_output+'/'+label+'_'+outshort+'.xlsx')
                    print "Writting table "+label+"_"+outshort+".xlsx"
                    sys.stdout.flush()

            df = df.sort('p_value')
            df = df.sort('q_value')
            if sig == 'yes':
                df = df[df['significant'] == 'yes']
            else:
                df = df[df['p_value'] < sig]
            df = df.reset_index()
            df['gene'] = df['gene'].astype(str)
            tmp = pd.DataFrame(df.gene.str.split(',',1).tolist())
            if len(tmp) < 1:
                print "skipping empty file"
                continue
            tmp = pd.DataFrame(tmp.ix[:,0])
            tmp.columns = ['identifier']
            df = pd.concat([df,tmp], axis=1)
            df = pd.merge(df, bio_go, how='left', left_on='identifier', right_on='gene_name')
            df = pd.merge(df,KEGG, how='left', on='identifier') 

            if imp == 'isoform_exp.diff': # for isoform_exp.diff we want to have the transcript references
                gtf=age.readGTF(merged_fixed_gtf)
                t_id = age.retrieve_GTF_field('transcript_id',gtf)    
                n_ref = age.retrieve_GTF_field('nearest_ref',gtf)

                id_ref = pd.concat([t_id, n_ref], axis=1).drop_duplicates()
                #id_ref.columns = ['transcript_id','nearest_ref']

                df = pd.merge(id_ref, df, how='right', left_on='transcript_id', right_on='test_id')

            """for significant changes also report overlaps between the days, pair-wise, as well as go ontology enrichemnt for each table from DAVID"""
            if sig == 'yes':

                sample1 = df[['sample_1']]
                sample1.columns=['samples']
                sample2 = df[['sample_2']]
                sample2.columns=['samples']
                samples=pd.concat([sample1,sample2])
                samples=samples.drop_duplicates()
                samples=samples['samples'].tolist()

                if args.DAVID:
                    DAVIDall=pd.DataFrame()
                    #ogtf=age.readGTF(original_gtf)

                readyList=[]

                for sample1 in samples:
                    for sample2 in samples:
                        if sample1 != sample2:
                            if sample1+sample2 not in readyList :
                                if sample2+sample1 not in readyList :

                                    readyList.append(sample1+sample2)
                                    df_pair = df[df['sample_1'].isin([sample1,sample2])][df['sample_2'].isin([sample1,sample2])]
                                    if args.DAVID:
                                        print "\nPerforming DAVID enrichment analysis on "+sample1+' vs. '+sample2
                                        sys.stdout.flush()
                                        
                                        targets=name_id.copy()
                                        targets.columns=['gene_name','targets']
                                        
                                        background=targets['targets'].tolist()
 
                                        targets = pd.merge(df_pair, targets, how='left', left_on='identifier', right_on='gene_name')
                                        targets = targets[['targets']].dropna()
                                        targets = targets['targets'].tolist()                                       
                                        if len(targets) > 0: 
                                            dfDAVID=age.DAVIDenrich(DAVID_id, args.DAVIDcat, user=args.DAVIDuser, ids=targets, ids_bg=background, name_bg = 'all_RNAseq_genes', name = 'changed_genes', verbose=True)
                                            if dfDAVID is not None:
                                                dfDAVID['sheet_name'] = sample1+'|'+sample2
                                                dfDAVID['file_name'] = "_"+label+"_"+outshort+".xlsx" 
                                                DAVIDall=pd.concat([DAVIDall,dfDAVID])

                                    df_pair.drop(['test_id','index','gene_id','Unnamed: 0','identifier','gene_name'], axis=1, inplace=True)

                                    if imp not in ['gene_exp.diff','isoform_exp.diff']:
                                        df_pair.drop(['value_1','value_2','test_stat'], axis=1, inplace=True)

                                    if not args.TSVall:
                                        df_pair.to_excel(writer, sample1+'|'+sample2, index=False)
                                    else:                                
                                        df_pair.to_csv(TSVout+label+'_'+outshort+'_'+sample1+'_vs_'+sample2+'.tsv',sep="\t", index=False)                                    



            df.drop(['test_id','index','gene_id','Unnamed: 0','identifier','gene_name'], axis=1, inplace=True)

            if imp not in ['gene_exp.diff','isoform_exp.diff']:
                df.drop(['value_1','value_2','test_stat'], axis=1, inplace=True)

            if sig == 'yes':
                if not args.TSVall:
                    df.to_excel(writer, 'ALL', index=False)
                    writer.save()
                else:
                    df.to_csv(TSVout+label+'_'+outshort+'_ALL.tsv',sep="\t", index=False)
                
                if args.DAVID:
                    if len(DAVIDall) > 0:
                        print "Writing DAVID output tables"
                        sys.stdout.flush()
                        file_names=list(set(DAVIDall['file_name'].tolist()))
                        for f in file_names:
                            dfFile=DAVIDall[DAVIDall['file_name']==f]
                            catres=list(set(dfFile['categoryName'].tolist()))
                            for c in catres:
                                dfCAT=dfFile[dfFile['categoryName']==c]
                                writerD = pd.ExcelWriter(python_output+'/'+c+f)    
                                print "\nDoing %s:" %(c+f)
                                sys.stdout.flush()
                                for sheet in list(set(dfCAT['sheet_name'].tolist())):
                                    print sheet
                                    sys.stdout.flush()
                                    dfSHEET=dfCAT[dfCAT['sheet_name']==sheet]
                                    dfSHEET=age.id_nameDAVID(dfSHEET,name_id=name_id)
                                    dfSHEET=dfSHEET.drop(['sheet_name','file_name'],axis=1)
                                    dfSHEET.to_excel(writerD, sheet, index=False)                                        
                                writerD.save()


        if sig != 'yes':
            if sig >= 1:
                if args.TSV:
                    df.to_csv(python_output+'/'+outshort+'_'+'ALL.tsv',sep="\t", index=False)
                else:
                    df.to_excel(writer, outshort+'_'+'ALL', index=False)

            else:
                if not args.TSVall:
                    df.to_excel(writer, outshort+'_'+'ALL', index=False) 

            
    if sig != 'yes':
        if sig >= 1:
            if args.TSV:
                print "For "+str(label)+" files were saved as tsv" 
            else:
                writer.save()
        else:
            if not args.TSVall:
                writer.save()

print "\n\n*************************************\nDeveloped by the Bioinformatics Core Facility of the Max Planck Institute for Biology of Ageing \n\nbioinformatics@age.mpg.de\n\n"
sys.exit()
